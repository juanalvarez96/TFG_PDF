\cleardoublepage
\phantomsection
\chapter*{Resumen}
\addcontentsline{toc}{chapter}{Resumen}
 La aparición de la red social Twitter en el año 2006 llevó consigo un tremendo empujón a la Revolución Digital que ya se estaba viviendo desde finales del siglo 20. Como resultado, a día de hoy se twittean unos 6000 tweets cada segundo. Se estima que para el año 2020 la red social Twitter contará con 275 millones de usuarios en todo el mundo. Tal es la popularidad de Twitter que casi el 74\% de sus usuarios usan Twitter a diario para consultar las noticias del día a día. Se podría decir que la Revolución Digital ha convertido a Twitter en una parte de nuestras vidas. Es por estas razones que este proyecto tiene como objetivo desarrollar un clasificador con la habilidad de detectar el sarcasmo en textos cortos, como en tweets.\par
 El propósito de este proyecto es conseguir la detección automatizada de sarcasmo. El principal desafío a tener en cuenta es la detección de emociones en frases que contienen sentimiento. Para abordar este enorme reto, se ha diseñado un clasificador que posee tecnologías de~\ac{ml}, el cuál podrá aprender a detectar sarcasmo. También han sido necesarias herramientas capaces de procesar lenguaje natural (\ac{nlp}). Con el fin de obtener unos parámetros adecuados en el clasificador se han llevado a cabo pruebas para ver que características aportan información relevante sobre el sarcasmo al clasificador. Las mas notables fueron los ngramas, las características léxicas y~\ac{lda}. Además, se ha llevado a cabo un~\ac{gs} con el propósito de buscar los parámetros óptimos del clasificador. Esto ha consistido en obtener el F1 score (medida de cómo de bueno es el clasificador) para cada permutación de una tabla de parámetros a probar. Una vez se obtuvieron los mejores parámetros, la plataforma senpy fue usada para dar una interfaz intuitiva en la que un usuario puede introducir texto y el clasificador indica si el texto tiene sarcasmo.\par
 Para terminar, los resultados obtenidos han oscilado, presentando un mínimo F1 score de $90.22$\% y un máximo de $96.68$\%. Esta diferencia se debe a las diferentes características extraídas y a los parámetros usados. En realidad, cuantas mas características son extraídas, peor es la capacidad del clasificador de generalizar. Y esto se traduce en que la precisión del clasificador disminuye. Este fenómeno también se conoce como overfitting.
\vfill
\textbf{Palabras clave:} Sarcasmo, Twitter, Machine Learning, Big Data, Python, NLP, Detección de Sarcasmo, Sentimientos, Emociones y Análisis. 